<?xml version="1.0" encoding="UTF-8"?>
<!--
  Story Context: RAG API Endpoint (Story 4.4)
  Auto-generated technical context for developer implementation
-->
<story-context id="4-4-rag-api-endpoint">
  
  <metadata>
    <story-key>4-4-rag-api-endpoint</story-key>
    <epic-id>4</epic-id>
    <story-id>4.4</story-id>
    <status>drafted</status>
    <title>RAG API Endpoint</title>
  </metadata>

  <story>
    <asA>developer</asA>
    <iWant>to build the RAG API endpoint using Mastra.AI Agents and Tools</iWant>
    <soThat>the frontend can get context-aware responses from Ursa (the conversational RAG agent)</soThat>
  </story>

  <acceptance-criteria>
    <criterion id="1">
      Given the Mastra.AI backend service, when I send a POST request to the `/api/rag` endpoint with a query and context (`personal` or `project`), then the service uses the appropriate documents from the vector database to generate a response, and the response is returned in a JSON format.
    </criterion>
    <criterion id="2">
      Given a RAG query request, when the context is `personal`, then the agent retrieves embeddings from `_content/personal/*.md` documents.
    </criterion>
    <criterion id="3">
      Given a RAG query request, when the context is `project`, then the agent retrieves embeddings from `_content/projects/*.md` documents.
    </criterion>
    <criterion id="4">
      Given the Mastra.AI agent, when processing a query, then it uses the `VectorQueryTool` (from Story 4.2) to retrieve relevant context before generating responses.
    </criterion>
    <criterion id="5">
      Given the RAG agent responds, when using GLM 4.5 Air for generation, then it maintains Ursa's personality and delivers helpful, accurate answers.
    </criterion>
  </acceptance-criteria>

  <tasks>
    <task id="1" ac-ref="1,4,5">
      <summary>Create Mastra Agent</summary>
      <subtasks>
        <subtask>Create `backend/src/agents/ursa-agent.ts`</subtask>
        <subtask>Define Ursa agent using Mastra's `Agent` class</subtask>
        <subtask>Configure with GLM 4.5 Air model (via Hugging Face)</subtask>
        <subtask>Set agent instructions/personality from Story 2.2 context</subtask>
        <subtask>Register `VectorQueryTool` (from Story 4.2) with the agent</subtask>
      </subtasks>
    </task>
    <task id="2" ac-ref="2,3">
      <summary>Implement Context Filtering Logic</summary>
      <subtasks>
        <subtask>Create filter helper in `backend/src/services/rag-context.ts`</subtask>
        <subtask>Implement metadata-based filtering for `personal` vs `project` context</subtask>
        <subtask>Pass context filter to `VectorQueryTool.execute()`</subtask>
      </subtasks>
    </task>
    <task id="3" ac-ref="1">
      <summary>Build tRPC RAG Endpoint</summary>
      <subtasks>
        <subtask>Create `backend/src/api/rag.ts`</subtask>
        <subtask>Define `ragQuery` mutation with Zod schema (query, context)</subtask>
        <subtask>Orchestrate: filter determination → VectorQueryTool → agent.generate()</subtask>
        <subtask>Return JSON: `{ response: string, sources?: string[] }`</subtask>
      </subtasks>
    </task>
    <task id="4" ac-ref="1-5">
      <summary>Test RAG Flow</summary>
      <subtasks>
        <subtask>Unit test: Context filtering logic</subtask>
        <subtask>Integration test: End-to-end RAG query (personal + project contexts)</subtask>
        <subtask>Manual verification: Query examples from frontend (via tRPC client)</subtask>
      </subtasks>
    </task>
  </tasks>

  <artifacts>
    <docs>
      <artifact>
        <path>docs/architecture.md</path>
        <title>Architecture</title>
        <section>Epic to Architecture Mapping</section>
        <snippet>Backend \u0026 Data Infrastructure uses Mastra.AI for RAG, tRPC API, Supabase for Vector DB. Hugging Face provides GLM 4.5 Air for generation, Qwen3 for embeddings.</snippet>
      </artifact>
      <artifact>
        <path>docs/epics.md</path>
        <title>Epics</title>
        <section>Story 4.4: RAG API Endpoint</section>
        <snippet>Core Mastra.AI logic for RAG agent. POST to `/api/rag` with query + context (personal/project), returns JSON response using vector DB documents.</snippet>
      </artifact>
      <artifact>
        <path>docs/sprint-artifacts/4-2-vector-database-ingestion.md</path>
        <title>Story 4.2 Completion</title>
        <section>Learnings from Story 4.2</section>
        <snippet>VectorQueryTool created at backend/src/tools/vector-query.ts using createTool(). Local embeddings via bge-small-en-v1.5 (384 dims). Supabase embeddings table with pgvector, 65 chunks ingested.</snippet>
      </artifact>
    </docs>

    <code>
      <artifact>
        <path>backend/src/tools/vector-query.ts</path>
        <kind>tool</kind>
        <symbol>vectorQueryTool</symbol>
        <lines>6-43</lines>
        <reason>REUSE THIS TOOL - already implements vector search. Created via createTool() with id/description/inputSchema/execute. Exports vectorQueryTool for agent registration.</reason>
      </artifact>
      <artifact>
        <path>backend/src/services/embeddings.ts</path>
        <kind>service</kind>
        <symbol>generateEmbedding</symbol>
        <reason>Local embedding generation (bge-small-en-v1.5, 384 dims). Used by VectorQueryTool to convert query text to vectors.</reason>
      </artifact>
      <artifact>
        <path>backend/src/services/supabase.ts</path>
        <kind>service</kind>
        <symbol>supabase</symbol>
        <reason>Supabase client configured with pgvector support. Used for vector similarity search (match_documents RPC).</reason>
      </artifact>
      <artifact>
        <path>backend/src/api/email.ts</path>
        <kind>api-router</kind>
        <symbol>emailRouter</symbol>
        <lines>23-50</lines>
        <reason>Example tRPC router pattern. Follow this structure for ragRouter: initTRPC.create(), define schema with Zod, create procedure with mutation/query.</reason>
      </artifact>
      <artifact>
        <path>backend/src/services/config.ts</path>
        <kind>service</kind>
        <symbol>config</symbol>
        <reason>Environment config with API keys (HUGGINGFACE_API_KEY for GLM 4.5 Air model).</reason>
      </artifact>
    </code>

    <dependencies>
      <node>
        <package name="@mastra/core" version="^0.24.3">Core Mastra framework - Agent class, createTool()</package>
        <package name="@trpc/server" version="^11.7.1">tRPC API framework for type-safe endpoints</package>
        <package name="@supabase/supabase-js" version="^2.84.0">Supabase client for vector DB operations</package>
        <package name="@huggingface/transformers" version="^3.8.0">Local transformers for embeddings (bge-small-en-v1.5)</package>
        <package name="zod" version="^4.1.12">Schema validation for tRPC inputs</package>
        <package name="dotenv" version="^17.2.3">Environment variable management</package>
      </node>
    </dependencies>
  </artifacts>

  <interfaces>
    <interface>
      <name>vectorQueryTool</name>
      <kind>Mastra Tool (createTool)</kind>
      <signature>
        createTool({
          id: 'vector-query',
          description: 'Search for relevant information in the knowledge base about Vansh and his projects.',
          inputSchema: z.object({
            query: z.string(),
            context: z.enum(['personal', 'project']),
            limit: z.number().optional().default(5)
          }),
          execute: async ({ context }) => { ... }
        })
      </signature>
      <path>backend/src/tools/vector-query.ts</path>
    </interface>
    <interface>
      <name>tRPC Router Pattern</name>
      <kind>API Router</kind>
      <signature>
        const t = initTRPC.create();
        export const router = t.router({
          procedureName: t.procedure
            .input(zodSchema)
            .mutation(async ({ input }) => { ... })
        });
      </signature>
      <path>backend/src/api/email.ts</path>
    </interface>
    <interface>
      <name>Mastra Agent Constructor</name>
      <kind>Agent Definition</kind>
      <signature>
        import { Agent } from '@mastra/core';
        const agent = new Agent({
          name: 'agent-name',
          instructions: 'System prompt/personality',
          model: 'huggingface/zai-org/GLM-4.5-Air',
          tools: { toolName: toolInstance }  // Pass tools as object
        });
      </signature>
      <path>New file: backend/src/agents/ursa-agent.ts</path>
    </interface>
  </interfaces>

  <constraints>
    <constraint>
      <category>Architecture</category>
      <rule>Use Mastra.AI Agent class with tools parameter for agent definition. Tools are passed as object: { toolName: toolInstance }</rule>
    </constraint>
    <constraint>
      <category>Tool Registration</category>
      <rule>Import vectorQueryTool from backend/src/tools/vector-query.ts. DO NOT recreate - it already exists from Story 4.2.</rule>
    </constraint>
    <constraint>
      <category>Models</category>
      <rule>Use GLM 4.5 Air (zai-org/GLM-4.5-Air via Hugging Face) for agent text generation. Embeddings use local bge-small-en-v1.5 (384 dims) - already configured.</rule>
    </constraint>
    <constraint>
      <category>Context Filtering</category>
      <rule>Filter vector search results based on metadata.source field in Supabase: personal context = _content/personal/*.md, project context = _content/projects/*.md</rule>
    </constraint>
    <constraint>
      <category>tRPC API Pattern</category>
      <rule>Follow tRPC router pattern from email.ts: initTRPC.create(), define Zod schema, use t.procedure.input(schema).mutation()</rule>
    </constraint>
    <constraint>
      <category>Personality</category>
      <rule>Agent instructions must reflect Ursa's personality from Story 2.2: Helpful, conversational, knowledgeable about Vansh's work. Adapt tone based on context (personal = casual, project = technical).</rule>
    </constraint>
    <constraint>
      <category>Testing</category>
      <rule>Use Jest (already configured in jest.config.js). Write unit tests for context filtering, integration tests for end-to-end RAG flow.</rule>
    </constraint>
  </constraints>

  <tests>
    <standards>
Testing uses Jest with ts-jest configuration (backend/jest.config.js). Follow established testing patterns: unit tests for isolated logic (context filtering helper), integration tests for complete workflows (RAG query flow). Mock Mastra Agent and tools in tests - see backend/src/tools/__tests__/vector-query.test.ts for tool testing pattern.
    </standards>
    <test-ideas>
      <idea>Unit Test: rag-context.ts helper - verify correct metadata filter construction for personal/project contexts</idea>
      <idea>Integration Test: Complete RAG flow - mock query → verify VectorQueryTool called → verify agent.generate() invoked → validate response format</idea>
      <idea>Manual Test: Use tRPC client from frontend to query both contexts, verify relevant results returned</idea>
    </test-ideas>
  </tests>

  <mastra-ai-research>
    <key-pattern name="Agent Creation">
      <summary>Mastra agents use `new Agent()` constructor with configuration object</summary>
      <code-pattern>
        import { Agent } from '@mastra/core';
        const agent = new Agent({
          name: 'unique-agent-name',
          instructions: 'System prompt defining behavior and personality',
          model: 'provider/model-name',  // e.g., 'huggingface/zai-org/GLM-4.5-Air'
          tools: { toolName: toolInstance }  // Tools as object, not array
        });
      </code-pattern>
      <source>https://mastra.ai/agents - Web research + documentation</source>
    </key-pattern>
    <key-pattern name="Tool Definition">
      <summary>Tools created via createTool() from @mastra/core</summary>
      <code-pattern>
        import { createTool } from '@mastra/core';
        import { z } from 'zod';
        
        const myTool = createTool({
          id: 'unique-tool-id',
          description: 'What the tool does - helps agent decide when to use it',
          inputSchema: z.object({ /* Zod schema for inputs */ }),
          outputSchema: z.string(),  // Optional output type
          execute: async ({ context }) => {
            // context contains parsed input based on inputSchema
            // return tool result
          }
        });
      </code-pattern>
      <source>backend/src/tools/vector-query.ts - Existing implementation + Mastra docs</source>
    </key-pattern>
    <key-pattern name="Tool Registration">
      <summary>Tools passed to agent as object (key-value pairs)</summary>
      <code-pattern>
        import { vectorQueryTool } from './tools/vector-query';
        
        const agent = new Agent({
          name: 'ursa',
          model: 'huggingface/zai-org/GLM-4.5-Air',
          tools: {
            vectorQuery: vectorQueryTool  // Tool name as key, instance as value
          }
        });
      </code-pattern>
      <source>https://mastra.ai/docs - Agent tools parameter accepts object format</source>
    </key-pattern>
    <key-pattern name="Agent Execution">
      <summary>Use agent.generate() for text responses</summary>
      <code-pattern>
        const response = await agent.generate({
          messages: [{ role: 'user', content: userQuery }]
        });
        // Agent automatically decides when to call tools based on query
        // Returns final text response after tool orchestration
      </code-pattern>
      <source>Mastra.AI documentation - Agent reasoning and tool calling</source>
    </key-pattern>
  </mastra-ai-research>

</story-context>
