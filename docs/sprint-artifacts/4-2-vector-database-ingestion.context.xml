<story-context id="portfolio2.0/docs/sprint-artifacts/4-2-vector-database-ingestion.context" v="1.0">
  <metadata>
    <epicId>4</epicId>
    <storyId>2</storyId>
    <title>Vector Database & Ingestion</title>
    <status>drafted</status>
    <generatedAt>2025-11-20</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/sprint-artifacts/4-2-vector-database-ingestion.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>developer</asA>
    <iWant>to set up a vector database and create a modular ingestion system using Mastra Tools</iWant>
    <soThat>the RAG agent has a scalable source of knowledge that can be easily extended (e.g., for email leads)</soThat>
    <tasks>
- [ ] Setup Supabase & Dependencies (AC: 1)
  - [ ] Install `@supabase/supabase-js` and Mastra dependencies
  - [ ] Configure Supabase client in `backend/src/services/supabase.ts`
  - [ ] Verify connection using keys from Story 4.3
- [ ] Implement Embedding Service (AC: 3)
  - [ ] Create `backend/src/services/embeddings.ts`
  - [ ] Implement integration with Hugging Face (Qwen3 Embedding 8B)
  - [ ] Create helper for chunking markdown content
- [ ] Create Mastra Vector Tool (AC: 2, 4)
  - [ ] Create `backend/src/tools/vector-query.ts`
  - [ ] Define `VectorQueryTool` class extending Mastra Tool base
  - [ ] Implement `execute` method to search Supabase
  - [ ] Define input schema (query, context, limit)
- [ ] Build Modular Ingestion System (AC: 3, 4)
  - [ ] Create `backend/src/services/ingestion/` directory
  - [ ] Define `IngestionSource` interface (OOP pattern)
  - [ ] Implement `MarkdownSource` class for `_content/` files
  - [ ] Create `backend/src/scripts/ingest-data.ts` main script
  - [ ] Script should iterate all sources and process them
- [ ] Test Ingestion & Retrieval (AC: 1, 2, 3)
  - [ ] Run ingestion script on sample markdown
  - [ ] Verify data in Supabase dashboard
  - [ ] Write unit test for `VectorQueryTool` to verify retrieval
    </tasks>
  </story>

  <acceptanceCriteria>
1.  **Given** a Supabase project
    *   **When** the backend connects
    *   **Then** it can store and retrieve vector embeddings using `pgvector`.
2.  **Given** the Mastra.AI backend
    *   **When** the agent needs to retrieve information
    *   **Then** it uses a dedicated **Mastra Tool** (`VectorQueryTool`) to query the database.
3.  **Given** markdown documents in `_content/personal` and `_content/projects`
    *   **When** the ingestion script is run
    *   **Then** the documents are chunked, embedded (using Qwen3 via Hugging Face), and stored in Supabase with correct metadata.
4.  **Given** the ingestion system
    *   **When** new data types are added (future requirement)
    *   **Then** the system is modular/OOP-based to allow easy extension without rewriting core logic.
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/architecture.md</path>
        <title>Architecture</title>
        <section>Data Architecture</section>
        <snippet>
The primary data persistence for the AI agents will be a vector database hosted on Supabase.
*   **Table**: `embeddings`
*   **Columns**: `id`, `content`, `embedding` (vector), `metadata` (JSONB), `created_at`
        </snippet>
      </doc>
      <doc>
        <path>docs/epics.md</path>
        <title>Epic Breakdown</title>
        <section>Story 4.2: Vector Database & Ingestion</section>
        <snippet>
*   **Mastra.AI Integration:** Implement the RAG retrieval as a **Mastra Tool** (e.g., `VectorQueryTool`) that the agent can invoke.
*   **Ingestion:** Create a modular ingestion script/workflow that processes markdown.
*   **Database:** Use Supabase (pgvector).
*   **Models:** Use the locked-in models (Qwen3 for embeddings) via Hugging Face integration.
        </snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>backend/src/services/config.ts</path>
        <kind>configuration module</kind>
        <symbol>config</symbol>
        <lines>all</lines>
        <reason>Provides validated environment variables (Supabase URL/Key, Hugging Face API Key)</reason>
      </artifact>
    </code>
    <dependencies>
      <ecosystem name="node">
        <package name="@supabase/supabase-js" version="latest" note="Supabase client" />
        <package name="@mastra/core" version="latest" note="Mastra.AI core framework" />
        <package name="pgvector" version="latest" note="PostgreSQL vector extension support" />
      </ecosystem>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint>Use Mastra.AI Tool pattern (createVectorQueryTool)</constraint>
    <constraint>Use Supabase with pgvector extension</constraint>
    <constraint>Use Qwen3 Embedding 8B model via Hugging Face</constraint>
    <constraint>Implement modular/OOP ingestion system (IngestionSource interface)</constraint>
    <constraint>Store metadata: source_file, project_id, type</constraint>
  </constraints>

  <interfaces>
    <interface>
      <name>IngestionSource</name>
      <kind>TypeScript Interface</kind>
      <signature>
interface IngestionSource {
  name: string;
  fetchDocuments(): Promise&lt;Document[]&gt;;
}
      </signature>
      <path>backend/src/services/ingestion/types.ts</path>
    </interface>
    <interface>
      <name>VectorQueryTool</name>
      <kind>Mastra Tool</kind>
      <signature>
execute(input: { query: string; context: 'personal' | 'project'; limit?: number }): Promise&lt;string&gt;
      </signature>
      <path>backend/src/tools/vector-query.ts</path>
    </interface>
  </interfaces>

  <tests>
    <standards>
      Verify Supabase connection and pgvector extension. Test embedding generation with Qwen3. Test ingestion script with sample markdown. Verify VectorQueryTool retrieval logic.
    </standards>
    <locations>
      <location>Supabase Dashboard: Check 'embeddings' table population</location>
      <location>Unit Test: backend/src/tools/__tests__/vector-query.test.ts</location>
      <location>Manual Run: npm run ingest-data</location>
    </locations>
    <ideas>
      <idea>Mock Hugging Face API for unit tests</idea>
      <idea>Test chunking logic with various markdown structures</idea>
      <idea>Verify metadata filtering in VectorQueryTool</idea>
    </ideas>
  </tests>
</story-context>
